{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 serpapi biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARJOvSdn5DeK",
        "outputId": "3b40a195-3a4a-4547-94da-a12909cee658"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
            "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython, serpapi\n",
            "Successfully installed biopython-1.86 serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "J92ieGV9zfoY",
        "outputId": "d605171b-a25f-40da-b248-2d8973cb4566"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJCT_UVuzW4V",
        "outputId": "a1ce01b6-aec3-423f-aeba-7ac2e11db8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to cleaned_neurologists2.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "INPUT_PATH = \"/content/drive/MyDrive/neurologistsFileSlightlyBigger.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/cleaned_neurologists2.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "TEXT_COLS = [\"First name\", \"Job position\", \"Company name\", \"Industry\", \"LinkedIn\"]\n",
        "\n",
        "for col in TEXT_COLS:\n",
        "    if col in df.columns:\n",
        "        df[col] = (\n",
        "            df[col]\n",
        "            .astype(str)\n",
        "            .str.lower()\n",
        "            .str.strip()\n",
        "        )\n",
        "\n",
        "SPECIALTY_KEYWORDS = {\n",
        "    \"cognitive_neurology\": [\"cognitive\", \"memory\", \"dementia\"],\n",
        "    \"neuro_ophthalmology\": [\"ophthalmology\", \"vision\", \"eye\"],\n",
        "    \"alzheimers\": [\"alzheimer\"],\n",
        "    \"movement_disorders\": [\"movement\", \"parkinson\"],\n",
        "    \"research\": [\"research\", \"scientist\", \"professor\"]\n",
        "}\n",
        "\n",
        "def extract_specialties(title):\n",
        "    found = []\n",
        "    for specialty, keywords in SPECIALTY_KEYWORDS.items():\n",
        "        for kw in keywords:\n",
        "            if kw in title:\n",
        "                found.append(specialty)\n",
        "                break\n",
        "    return \",\".join(found)\n",
        "\n",
        "df[\"specialties\"] = df[\"Job position\"].apply(extract_specialties)\n",
        "\n",
        "VAGUE_TITLES = [\"neurologist\", \"md\", \"physician\"]\n",
        "\n",
        "def needs_scraping(row):\n",
        "    LinkedIn_missing = row.get(\"LinkedIn\", \"\") in [\"\", \"nan\"]\n",
        "    vague_title = row.get(\"Job position\", \"\") in VAGUE_TITLES\n",
        "    Industry_blank = row.get(\"Industry\", \"\") in [\"\", \"nan\"]\n",
        "    return LinkedIn_missing or vague_title or Industry_blank\n",
        "\n",
        "df[\"needs_scraping\"] = df.apply(needs_scraping, axis=1)\n",
        "\n",
        "df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(\"Cleaned data saved to cleaned_neurologists2.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import search\n",
        "import os\n",
        "\n",
        "SERPAPI_KEY = \"8c877b3b662e5dde56305c33b1b9b54bf59016ddf0b1f0b5551f2221ef7810c8\"\n",
        "\n",
        "def google_search(query):\n",
        "    params = {\n",
        "        \"engine\": \"google\",\n",
        "        \"q\": query,\n",
        "        \"api_key\": SERPAPI_KEY,\n",
        "        \"num\": 10\n",
        "    }\n",
        "\n",
        "    results = search(params)\n",
        "    snippets = []\n",
        "\n",
        "    for r in results.get(\"organic_results\", []):\n",
        "        snippets.append(r.get(\"snippet\", \"\").lower())\n",
        "\n",
        "    return \" \".join(snippets)\n",
        "\n",
        "\n",
        "def keyword_signal(text, keywords):\n",
        "    return int(any(k in text for k in keywords))\n",
        "\n",
        "\n",
        "from Bio import Entrez\n",
        "import re\n",
        "\n",
        "Entrez.email = \"your_email@example.com\"\n",
        "\n",
        "def pubmed_alzheimers_count(author_name):\n",
        "    query = f'{author_name}[Author] AND (Alzheimer OR dementia)'\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=50)\n",
        "    record = Entrez.read(handle)\n",
        "    return int(record[\"Count\"])\n",
        "\n",
        "def pubmed_recent_keywords(author_name):\n",
        "    query = f'{author_name}[Author] AND (\"2019\"[PDAT] : \"3000\"[PDAT])'\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=10)\n",
        "    ids = Entrez.read(handle)[\"IdList\"]\n",
        "\n",
        "    keywords = set()\n",
        "\n",
        "    for pid in ids:\n",
        "        fetch = Entrez.efetch(db=\"pubmed\", id=pid, rettype=\"abstract\", retmode=\"text\")\n",
        "        text = fetch.read().lower()\n",
        "        for k in [\"alzheimers\", \"dementia\", \"vr\", \"eye tracking\", \"hci\"]:\n",
        "            if k in text:\n",
        "                keywords.add(k)\n",
        "\n",
        "    return list(keywords)"
      ],
      "metadata": {
        "id": "4zNlIB6H5slc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "\n",
        "INPUT_PATH = \"/content/drive/MyDrive/cleaned_neurologists2.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/scraped_info.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "def scrape_signals(name, institution):\n",
        "    query = f\"{name} {institution} neurologist research\"\n",
        "\n",
        "    google_text = google_search(query)\n",
        "\n",
        "    alz_papers = pubmed_alzheimers_count(name)\n",
        "    recent_keywords = pubmed_recent_keywords(name)\n",
        "\n",
        "    return {\n",
        "        \"mentions_alzheimers\": keyword_signal(google_text, [\"alzheimer\"]),\n",
        "        \"mentions_dementia\": keyword_signal(google_text, [\"dementia\"]),\n",
        "        \"cognitive_decline\": keyword_signal(google_text, [\"cognitive decline\"]),\n",
        "        \"eye_tracking\": keyword_signal(google_text, [\"eye tracking\"]),\n",
        "        \"vr_ar\": keyword_signal(google_text, [\"virtual reality\", \"vr\", \"augmented reality\"]),\n",
        "        \"neuro_ophthalmology\": keyword_signal(google_text, [\"neuro-ophthalmology\"]),\n",
        "        \"alzheimers_papers\": alz_papers,\n",
        "        \"recent_keywords\": recent_keywords\n",
        "    }\n",
        "\n",
        "\n",
        "scraped_rows = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    signals = scrape_signals(row[\"First name\"], row[\"Company name\"])\n",
        "    scraped_rows.append({**row.to_dict(), **signals})\n",
        "\n",
        "scraped_df = pd.DataFrame(scraped_rows)\n",
        "scraped_df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(\"Scraped enrichment data saved to scraped_info.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVwBlP4515DO",
        "outputId": "086a892e-7c0a-4fe2-a568-76f4352b3ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped enrichment data saved to scraped_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "INPUT_PATH = \"/content/drive/MyDrive/scraped_info.csv\"\n",
        "TOP_100_PATH = \"/content/drive/MyDrive/top_100_neurologists.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "def calculate_score(row):\n",
        "    score = 0\n",
        "\n",
        "    if row[\"mentions_alzheimers\"]:\n",
        "        score += 50\n",
        "    if \"cognitive_neurology\" in str(row[\"specialties\"]):\n",
        "        score += 40\n",
        "    if row[\"mentions_dementia\"]:\n",
        "        score += 30\n",
        "    if row[\"eye_tracking\"]:\n",
        "        score += 25\n",
        "    if row[\"vr_ar\"]:\n",
        "        score += 20\n",
        "    if row[\"neuro_ophthalmology\"]:\n",
        "        score += 20\n",
        "\n",
        "    papers = row[\"alzheimers_papers\"]\n",
        "    if papers >= 10:\n",
        "        score += 50\n",
        "    elif papers >= 5:\n",
        "        score += 30\n",
        "\n",
        "    keyword_matches = len(set(row[\"recent_keywords\"].strip(\"[]\").split(\",\")))\n",
        "    if keyword_matches >= 3:\n",
        "        score += 40\n",
        "\n",
        "    return score\n",
        "\n",
        "df[\"relevance_score\"] = df.apply(calculate_score, axis=1)\n",
        "\n",
        "top_100 = df.sort_values(\n",
        "    by=\"relevance_score\",\n",
        "    ascending=False\n",
        ").head(100)\n",
        "\n",
        "top_100.to_csv(TOP_100_PATH, index=False)\n",
        "\n",
        "print(\"Top 100 neurologists saved to top_100_neurologists.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnjgNvz_2a6N",
        "outputId": "cce30abe-4f89-410a-9a9f-4c6e9a792a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100 neurologists saved to top_100_neurologists.csv\n"
          ]
        }
      ]
    }
  ]
}